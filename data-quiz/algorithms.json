{
  "title": "Data Structures & Algorithms",
  "description": "Test your knowledge of fundamental data structures, algorithm design, complexity analysis, and problem-solving techniques.",
  "difficulty": "Intermediate to Advanced",
  "questions": [
    {
      "id": 1,
      "question": "Which data structure operates on the LIFO (Last-In-First-Out) principle?",
      "options": [
        "Queue",
        "Stack",
        "Linked List",
        "Binary Tree"
      ],
      "answer": 1,
      "explanation": "A stack operates on the Last-In-First-Out (LIFO) principle, where the last element added is the first one to be removed."
    },
    {
      "id": 2,
      "question": "What is the time complexity of searching for an element in a balanced binary search tree?",
      "options": [
        "O(1)",
        "O(log n)",
        "O(n)",
        "O(n log n)"
      ],
      "answer": 1,
      "explanation": "Searching in a balanced binary search tree has a time complexity of O(log n) because at each step, we eliminate roughly half of the remaining elements."
    },
    {
      "id": 3,
      "question": "What does the following Python code do?\n\ndef mystery(n):\n    if n <= 1:\n        return n\n    return mystery(n-1) + mystery(n-2)",
      "options": [
        "Calculates the factorial of n",
        "Calculates the nth Fibonacci number",
        "Calculates the sum of numbers from 1 to n",
        "Checks if n is a prime number"
      ],
      "answer": 1,
      "explanation": "This recursive function calculates the nth Fibonacci number. It returns n for base cases (n ≤ 1) and for other cases, it returns the sum of the (n-1)th and (n-2)th Fibonacci numbers."
    },
    {
      "id": 4,
      "question": "Which sorting algorithm has a best-case time complexity of O(n)?",
      "options": [
        "Merge Sort",
        "Quick Sort",
        "Bubble Sort",
        "Insertion Sort"
      ],
      "answer": 3,
      "explanation": "Insertion Sort has a best-case time complexity of O(n) when the input array is already sorted or nearly sorted. It makes only a single pass through the array with minimal comparisons."
    },
    {
      "id": 5,
      "question": "What is the space complexity of the following JavaScript function?\n\nfunction sum(arr) {\n  let total = 0;\n  for (let i = 0; i < arr.length; i++) {\n    total += arr[i];\n  }\n  return total;\n}",
      "options": [
        "O(1)",
        "O(log n)",
        "O(n)",
        "O(n²)"
      ],
      "answer": 0,
      "explanation": "This function uses only a fixed amount of extra space (the 'total' variable and loop counter 'i') regardless of the input size, so its space complexity is O(1) - constant space."
    },
    {
      "id": 6,
      "question": "Which data structure would be most efficient for implementing a priority queue?",
      "options": [
        "Array",
        "Linked List",
        "Heap",
        "Stack"
      ],
      "answer": 2,
      "explanation": "A heap (specifically a binary heap) is the most efficient standard data structure for implementing a priority queue. It provides O(log n) time for insertions and deletions, and O(1) time to find the minimum/maximum element."
    },
    {
      "id": 7,
      "question": "What is the output of the following JavaScript code?\n\nfunction mystery(arr) {\n  if (arr.length <= 1) return arr;\n  const pivot = arr[0];\n  const left = arr.slice(1).filter(x => x < pivot);\n  const right = arr.slice(1).filter(x => x >= pivot);\n  return [...mystery(left), pivot, ...mystery(right)];\n}\n\nconsole.log(mystery([3, 1, 4, 1, 5, 9, 2, 6]));",
      "options": [
        "[1, 1, 2, 3, 4, 5, 6, 9]",
        "[9, 6, 5, 4, 3, 2, 1, 1]",
        "[3, 1, 4, 1, 5, 9, 2, 6]",
        "[6, 2, 9, 5, 1, 4, 1, 3]"
      ],
      "answer": 0,
      "explanation": "This function implements the quicksort algorithm. It recursively sorts elements less than the pivot, places the pivot in the middle, and sorts elements greater than or equal to the pivot. The output is the sorted array [1, 1, 2, 3, 4, 5, 6, 9]."
    },
    {
      "id": 8,
      "question": "What is the time complexity of the worst-case scenario for quicksort?",
      "options": [
        "O(n)",
        "O(n log n)",
        "O(n²)",
        "O(2^n)"
      ],
      "answer": 2,
      "explanation": "In the worst-case scenario (when the pivot is always the smallest or largest element), quicksort has a time complexity of O(n²). This happens when the array is already sorted or reverse sorted."
    },
    {
      "id": 9,
      "question": "Which of the following traversal methods for a binary tree visits the root node first, then the left subtree, and finally the right subtree?",
      "options": [
        "In-order traversal",
        "Pre-order traversal",
        "Post-order traversal",
        "Level-order traversal"
      ],
      "answer": 1,
      "explanation": "Pre-order traversal visits the root node first, then recursively traverses the left subtree, and finally recursively traverses the right subtree."
    },
    {
      "id": 10,
      "question": "What is the primary advantage of a hash table over an array?",
      "options": [
        "Hash tables always use less memory than arrays",
        "Hash tables provide O(1) average case time complexity for insertion, deletion, and lookup",
        "Hash tables maintain the order of elements",
        "Hash tables can only store string keys"
      ],
      "answer": 1,
      "explanation": "The primary advantage of hash tables is their O(1) average case time complexity for insertion, deletion, and lookup operations, which is much faster than the O(n) time required for arrays when the index is not known."
    },
    {
      "id": 11,
      "question": "What is dynamic programming?",
      "options": [
        "A programming paradigm where code changes behavior during runtime",
        "A method for solving complex problems by breaking them down into simpler subproblems and storing the results",
        "A technique for writing self-modifying code",
        "An approach to automatically generate optimized code at runtime"
      ],
      "answer": 1,
      "explanation": "Dynamic programming is a method for solving complex problems by breaking them down into simpler overlapping subproblems and storing the results of subproblems to avoid redundant calculations."
    },
    {
      "id": 12,
      "question": "What does the following JavaScript code compute?\n\nfunction compute(n) {\n  let result = 0;\n  for (let i = 1; i <= n; i++) {\n    for (let j = 1; j <= i; j++) {\n      result += 1;\n    }\n  }\n  return result;\n}",
      "options": [
        "n",
        "n²",
        "n × (n+1) / 2",
        "n × (n+1) × (2n+1) / 6"
      ],
      "answer": 2,
      "explanation": "This function adds 1 to the result for each iteration of the inner loop. The inner loop runs i times for each value of i from 1 to n. So the total number of iterations is 1 + 2 + 3 + ... + n, which is the sum of the first n natural numbers, equal to n × (n+1) / 2."
    },
    {
      "id": 13,
      "question": "What is the purpose of a breadth-first search algorithm?",
      "options": [
        "To find the shortest path between two nodes in a graph",
        "To sort elements in an array",
        "To find all leaf nodes in a tree",
        "To calculate the maximum depth of a tree"
      ],
      "answer": 0,
      "explanation": "Breadth-first search (BFS) explores all the vertices of a graph at the present depth level before moving on to vertices at the next depth level. When used on unweighted graphs, it finds the shortest path between two nodes."
    },
    {
      "id": 14,
      "question": "Which of the following is NOT a common graph representation?",
      "options": [
        "Adjacency Matrix",
        "Adjacency List",
        "Linked Representation",
        "Priority Queue Representation"
      ],
      "answer": 3,
      "explanation": "Priority Queue Representation is not a common way to represent graphs. The standard representations are Adjacency Matrix, Adjacency List, and sometimes Linked Representation or Edge List."
    },
    {
      "id": 15,
      "question": "What is the time complexity of inserting an element into a linked list if you have a reference to the insertion position?",
      "options": [
        "O(1)",
        "O(log n)",
        "O(n)",
        "O(n log n)"
      ],
      "answer": 0,
      "explanation": "Inserting an element into a linked list when you already have a reference to the insertion position is an O(1) operation, as it only requires changing a fixed number of pointers regardless of the list's size."
    },
    {
      "id": 16,
      "question": "What does the term 'greedy algorithm' refer to?",
      "options": [
        "An algorithm that uses excessive memory resources",
        "An algorithm that makes locally optimal choices at each step with the hope of finding a global optimum",
        "An algorithm that prioritizes speed over accuracy",
        "An algorithm that recursively breaks down problems into subproblems"
      ],
      "answer": 1,
      "explanation": "A greedy algorithm is one that makes the locally optimal choice at each step with the hope of finding a global optimum. Greedy algorithms don't always yield optimal solutions but are often used for approximation when optimal solutions are difficult to compute."
    },
    {
      "id": 17,
      "question": "Which data structure would you use to check if a string is a palindrome?",
      "options": [
        "Queue",
        "Stack",
        "Heap",
        "Any of these could work, but a stack is most common"
      ],
      "answer": 3,
      "explanation": "Any of these data structures could be used to check for palindromes, but a stack is a common choice. You can push the first half of the string onto a stack, then pop and compare with the second half. Alternatively, you could simply compare characters from both ends of the string."
    },
    {
      "id": 18,
      "question": "What is memoization in the context of algorithms?",
      "options": [
        "A technique to speed up programs by storing results of expensive function calls and returning the cached result when the same inputs occur again",
        "A method for organizing code into modular, reusable components",
        "A strategy for minimizing memory usage in recursive functions",
        "A design pattern for optimizing database queries"
      ],
      "answer": 0,
      "explanation": "Memoization is an optimization technique that speeds up programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again, avoiding redundant calculations."
    },
    {
      "id": 19,
      "question": "What will be the output of the following JavaScript code?\n\nfunction findUnique(arr) {\n  return arr.reduce((acc, val) => acc ^ val, 0);\n}\n\nconsole.log(findUnique([4, 2, 7, 2, 4]));",
      "options": [
        "0",
        "7",
        "4",
        "Error"
      ],
      "answer": 1,
      "explanation": "This function uses the XOR operation (^) to find a unique number in an array where all other numbers appear exactly twice. The XOR of a number with itself is 0, and XOR is commutative and associative. So, 4 ^ 2 ^ 7 ^ 2 ^ 4 = (4 ^ 4) ^ (2 ^ 2) ^ 7 = 0 ^ 0 ^ 7 = 7."
    },
    {
      "id": 20,
      "question": "What is the difference between a stable and unstable sorting algorithm?",
      "options": [
        "Stable algorithms maintain the original order of equal elements, while unstable algorithms might reorder equal elements",
        "Stable algorithms have guaranteed performance, while unstable algorithms have variable performance",
        "Stable algorithms use less memory, while unstable algorithms require more memory",
        "Stable algorithms always perform better than unstable algorithms"
      ],
      "answer": 0,
      "explanation": "A stable sorting algorithm maintains the relative order of equal elements from the input in the sorted output. An unstable sorting algorithm might reorder equal elements, changing their relative positions in the sorted output."
    }
  ]
}